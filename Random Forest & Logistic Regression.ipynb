{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Random Forest & Logistic Regression.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qbVLDFh43Ens"},"source":["## Library"]},{"cell_type":"code","metadata":{"id":"D82dfCgK2YP8"},"source":["import numpy as np\n","import pandas as pd\n","import time\n","import random\n","import functools\n","import sys"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s0_ghfHQ3IMZ"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"2UjwU_CP2YQI"},"source":["def get_mode(column):\n","    mode = []\n","    appear = dict((a, column.count(a)) for a in column)   # count appearance times of each key\n","    if max(appear.values()) == 1:       # if max time is 1\n","        return      # no mode here\n","    else:\n","        for k, v in appear.items():     # else, mode is the number which has max time\n","            if v == max(appear.values()):\n","                mode.append(k)\n","    return mode[0]  # return first number if has many modes\n","\n","def fill_missing_values(dataframe_list, column_no):     # dataframe in the form of a list of lists\n","    size = len(dataframe_list)\n","    column_data = [x[column_no] for x in dataframe_list]      # get that column\n","    while '?' in column_data:\n","        column_data.remove('?')\n","    mode = get_mode(column_data)\n","    for i in range(size):\n","        if dataframe_list[i][column_no] == '?':\n","            dataframe_list[i][column_no] = mode              # fill in mode\n","    return dataframe_list\n","\n","def get_discretization_data(data_column, class_label_column):\n","    size = len(data_column)\n","    result_list = []\n","    for i in range(size):\n","        result_list.append([data_column[i], class_label_column[i]])\n","    return result_list\n","\n","def replace_numerical(dataframe_list, column_no, walls):\n","    size = len(dataframe_list)\n","    num_spilt_point = len(walls)\n","    for i in range(size):\n","        if dataframe_list[i][column_no] > walls[num_spilt_point - 1]:\n","            dataframe_list[i][column_no] = num_spilt_point + 1\n","            continue\n","        for j in range(0, num_spilt_point):\n","            if dataframe_list[i][column_no] <= walls[j]:\n","                dataframe_list[i][column_no] = j + 1\n","                break\n","    return dataframe_list\n","\n","def replace_categorical(dataframe_list, column_no):\n","    size = len(dataframe_list)\n","    classes = set([x[column_no] for x in dataframe_list])\n","    classes_no = dict([(label, 0) for label in classes])\n","    j = 1\n","    for i in classes:\n","        classes_no[i] = j\n","        j += 1\n","    for i in range(size):\n","        dataframe_list[i][column_no] = classes_no[dataframe_list[i][column_no]]\n","    return dataframe_list, classes_no\n","\n","def discard(dataframe_list, discard_list):\n","    size = len(dataframe_list)\n","    length = len(dataframe_list[0])\n","    data_result = []\n","    for i in range(size):\n","        data_result.append([])\n","        for j in range(length):\n","            if j not in discard_list:\n","                data_result[i].append(dataframe_list[i][j])\n","    return data_result\n","\n","def pre_process(dataframe_list, attribute, value_type):\n","    column_num = len(dataframe_list[0])\n","    size = len(dataframe_list)\n","    class_column = [x[-1] for x in dataframe_list]\n","    discard_list = []\n","    for i in range(0, column_num - 1):\n","        data_column = [x[i] for x in dataframe_list]\n","\n","        # process missing values\n","        missing_values_ratio = data_column.count('?') / size\n","        if missing_values_ratio > 0.5:\n","            discard_list.append(i)\n","            continue\n","        elif missing_values_ratio > 0:\n","            dataframe_list = fill_missing_values(dataframe_list, i)\n","            data_column = [x[i] for x in dataframe_list]\n","\n","        # discretization\n","        if value_type[i] == 'numerical':\n","            discretization_data = get_discretization_data(data_column, class_column)\n","            block = Block(discretization_data)\n","            walls = partition(block)\n","            if len(walls) == 0:\n","                max_value = max(data_column)\n","                min_value = min(data_column)\n","                step = (max_value - min_value) / 3\n","                walls.append(min_value + step)\n","                walls.append(min_value + 2 * step)\n","            print(attribute[i] , \":\", walls)        # print out split points\n","            dataframe_list = replace_numerical(dataframe_list, i, walls)\n","        elif value_type[i] == 'categorical':\n","            dataframe_list, classes_no = replace_categorical(dataframe_list, i)\n","            print(attribute[i] , \":\", classes_no)   # print out replacement list\n","\n","    # discard\n","    if len(discard_list) > 0:\n","        dataframe_list = discard(data, discard_list)\n","        print(\"discard:\", discard_list)             # print out discard list\n","    return dataframe_list\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MgqlHrBa2YQO"},"source":["import csv\n","\n","\n","# Read dataset and convert into a list.\n","# path: directory of *.data file.\n","def read_data(path):\n","    data = []\n","    with open(path, 'r') as csv_file:\n","        reader = csv.reader(csv_file, delimiter=',')\n","        for line in reader:\n","            data.append(line)\n","        while [] in data:\n","            data.remove([])\n","    return data\n","\n","\n","# Read scheme file *.names and write down attributes and value types.\n","# path: directory of *.names file.\n","def read_scheme(path):\n","    with open(path, 'r') as csv_file:\n","        reader = csv.reader(csv_file, delimiter=',')\n","        attributes = next(reader)\n","        value_type = next(reader)\n","    return attributes, value_type\n","\n","\n","# convert string-type value into float-type.\n","# data: data list returned by read_data.\n","# value_type: list returned by read_scheme.\n","def str2numerical(data, value_type):\n","    #ct = 0\n","    #print(\"str2numerical\")\n","    size = len(data) \n","    columns = len(data[0])\n","    for i in range(size):\n","        #ct = 0\n","        for j in range(columns - 1):\n","            if value_type[j] == 'numerical' and data[i][j] != '?':\n","                #ct += 1\n","                data[i][j] = float(data[i][j])\n","        #print(\"ct: \",ct)\n","    return data\n","\n","\n","# Main method in this file, to get data list after processing and scheme list.\n","# data_path: tell where *.data file stores.\n","# scheme_path: tell where *.names file stores.\n","def read(data_path, scheme_path):\n","    data = read_data(data_path)\n","    attributes, value_type = read_scheme(scheme_path)\n","    data = str2numerical(data, value_type)\n","    return data, attributes, value_type"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"omGgrC7U2YQR"},"source":["import math\n","\n","\n","# A block to be split\n","# It has 4 member:\n","#   data: the data table with a column of continuous-valued attribute and a column of class label\n","#   size: number of data case in this table\n","#   number_of_classes: obviously, the number of class in this table\n","#   entropy: entropy of dataset\n","class Block:\n","    def __init__(self, data):\n","        self.data = data\n","        self.size = len(data)\n","        classes = set([x[1] for x in data])     # get distinct class labels in this table\n","        self.number_of_classes = len(set(classes))\n","        self.entropy = calculate_entropy(data)\n","\n","\n","# Calculate the entropy of dataset\n","# parameter data: the data table to be used\n","def calculate_entropy(data):\n","    number_of_data = len(data)\n","    classes = set([x[1] for x in data])\n","    class_count = dict([(label, 0) for label in classes])\n","    for data_case in data:\n","        class_count[data_case[1]] += 1      # count the number of data case of each class\n","    entropy = 0\n","    for c in classes:\n","        p = class_count[c] / number_of_data\n","        entropy -= p * math.log2(p)         # calculate information entropy by its formula, where the base is 2\n","    return entropy\n","\n","\n","# Compute Gain(A, T: S) mentioned in Dougherty, Kohavi & Sahami (1995), i.e. entropy gained by splitting original_block\n","#   into left_block and right_block\n","# original_block: the block before partition\n","# left_block: the block split which its value below boundary\n","# right_block: the block above boundary\n","def entropy_gain(original_block, left_block, right_block):\n","    gain = original_block.entropy - \\\n","            ((left_block.size / original_block.size) * left_block.entropy +\n","            (right_block.size / original_block.size) * right_block.entropy)\n","    return gain\n","\n","\n","# Get minimum entropy gain required for a split of original_block into 2 blocks \"left\" and \"right\", see Dougherty,\n","#   Kohavi & Sahami (1995)\n","# original_block: the block before partition\n","# left_block: the block split which its value below boundary\n","# right_block: the block above boundary\n","def min_gain(original_block, left_block, right_block):\n","    delta = math.log2(math.pow(3, original_block.number_of_classes) - 2) - \\\n","            (original_block.number_of_classes * original_block.entropy -\n","             left_block.number_of_classes * left_block.entropy -\n","             right_block.number_of_classes * right_block.entropy)\n","    gain_sup = math.log2(original_block.size - 1) / original_block.size + delta / original_block.size\n","    return gain_sup\n","\n","\n","# Identify the best acceptable value to split block\n","# block: a block of dataset\n","# Return value: a list of (boundary, entropy gain, left block, right block) or\n","#   None when it's unnecessary to split\n","def split(block):\n","    candidates = [x[0] for x in block.data]     # candidates is a list of values can be picked up as boundary\n","    candidates = list(set(candidates))          # get different values in table\n","    candidates.sort()                           # sort ascending\n","    candidates = candidates[1:]                 # discard smallest, because by definition no value is smaller\n","\n","    wall = []       # wall is a list storing final boundary\n","    for value in candidates:\n","        # split by value into 2 groups, below & above\n","        left_data = []\n","        right_data = []\n","        for data_case in block.data:\n","            if data_case[0] < value:\n","                left_data.append(data_case)\n","            else:\n","                right_data.append(data_case)\n","\n","        left_block = Block(left_data)\n","        right_block = Block(right_data)\n","\n","        gain = entropy_gain(block, left_block, right_block)\n","        threshold = min_gain(block, left_block, right_block)\n","\n","        # minimum threshold is met, the value is an acceptable candidate\n","        if gain >= threshold:\n","            wall.append([value, gain, left_block, right_block])\n","\n","    if wall:    # has candidate\n","        wall.sort(key=lambda wall: wall[1], reverse=True)   # sort descending by \"gain\"\n","        return wall[0]      # return best candidate with max entropy gain\n","    else:\n","        return None         # no need to split\n","\n","\n","# Top-down recursive partition of a data block, append boundary into \"walls\"\n","# block: a data block\n","def partition(block):\n","    walls = []\n","\n","    # inner recursive function, accumulate the partitioning values\n","    # sub_block: just a data block\n","    def recursive_split(sub_block):\n","        wall_returned = split(sub_block)        # binary partition, get bin boundary\n","        if wall_returned:                       # still can be spilt\n","            walls.append(wall_returned[0])      # record this partitioning value\n","            recursive_split(wall_returned[2])   # recursively process left block\n","            recursive_split(wall_returned[3])   # recursively split right block\n","        else:\n","            return                              # end of recursion\n","\n","    recursive_split(block)      # call inner function\n","    walls.sort()                # sort boundaries descending\n","    return walls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pSaAn0kt2YQT"},"source":["## Iris.csv"]},{"cell_type":"code","metadata":{"id":"vfiYyvJ-2YQY","outputId":"bac181d5-0203-43f0-e745-dc794e2c0912"},"source":["df = pd.read_csv('../dataset/iris.csv', header= None)\n","df.head()\n","rows = len(df)\n","cols = len(df.columns)\n","\n","df = df.values.tolist() #convert dataframe to list of lists\n","test_attribute = [0,1,2,3,4]\n","test_value_type = ['numerical', 'numerical', 'numerical','numerical', 'label']\n","test_data_after = pre_process(df, test_attribute, test_value_type)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["0 : [5.6, 6.2]\n","1 : [3.0, 3.4]\n","2 : [3.0, 4.8]\n","3 : [1.0, 1.8]\n"]}]},{"cell_type":"markdown","metadata":{"id":"RnrVnCen2YQd"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"8JNOSQdP2YQf"},"source":["data = pd.DataFrame (test_data_after)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lws82eV82YQh","outputId":"5913795e-ad55-4f50-98c1-7ea42f5f0260"},"source":["data.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  1  2  3            4\n","0  1  3  1  1  Iris-setosa\n","1  1  1  1  1  Iris-setosa\n","2  1  2  1  1  Iris-setosa\n","3  1  2  1  1  Iris-setosa\n","4  1  3  1  1  Iris-setosa"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"S4bZeVBA2YQk","outputId":"fee9de59-adc4-4384-a817-19fdd8f0b838"},"source":["data[4].unique()"],"execution_count":null,"outputs":[{"data":{"text/plain":["array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"avosRjX-2YQm"},"source":["X = data.drop(4, axis=1)\n","y = data[4]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uW105BP82YQn"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EAqxIxDh2YQo","outputId":"21452255-d585-4a89-b80c-ad27295459a8"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"RCqWjSHp2YQp","outputId":"a9f2f20e-a837-4846-96a9-9b0a8c5fa3e5"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 100.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","           Iris-setosa  Iris-versicolor  Iris-virginica  accuracy  macro avg  \\\n","precision          1.0              1.0             1.0       1.0        1.0   \n","recall             1.0              1.0             1.0       1.0        1.0   \n","f1-score           1.0              1.0             1.0       1.0        1.0   \n","support           19.0             15.0            16.0       1.0       50.0   \n","\n","           weighted avg  \n","precision           1.0  \n","recall              1.0  \n","f1-score            1.0  \n","support            50.0  \n","_______________________________________________\n","Confusion Matrix: \n"," [[19  0  0]\n"," [ 0 15  0]\n"," [ 0  0 16]]\n","\n","_______________________________________________\n","f1_score: \n"," 1.0\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"IppSGl8D2YQq"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"eXCkG6Tz2YQq"},"source":["X = data.drop(4, axis=1)\n","y = data[4]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zcS55KXV2YQs"},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwDlzESl2YQt","outputId":"413e288e-8e23-49e8-9716-d96fd945b0e0"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"-kNwiRbu2YQv","outputId":"832e2a38-ce5f-4165-8d58-a29bc8c2a326"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 90.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","           Iris-setosa  Iris-versicolor  Iris-virginica  accuracy  macro avg  \\\n","precision     0.950000         1.000000        0.800000       0.9   0.916667   \n","recall        1.000000         0.666667        1.000000       0.9   0.888889   \n","f1-score      0.974359         0.800000        0.888889       0.9   0.887749   \n","support      19.000000        15.000000       16.000000       0.9  50.000000   \n","\n","           weighted avg  \n","precision      0.917000  \n","recall         0.900000  \n","f1-score       0.894701  \n","support       50.000000  \n","_______________________________________________\n","Confusion Matrix: \n"," [[19  0  0]\n"," [ 1 10  4]\n"," [ 0  0 16]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9\n","\n"]}]},{"cell_type":"code","metadata":{"id":"9BzdMVDm2YQw","outputId":"76220ace-8424-4c2b-e533-f310d5aa4ee7"},"source":["lr_saga = LogisticRegression(solver='saga', max_iter = 1000) # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(max_iter=1000, solver='saga')"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"2XlM9TXE2YQy","outputId":"cb71b41a-5af1-4409-abd2-89286d863cfc"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test =lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 100.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","           Iris-setosa  Iris-versicolor  Iris-virginica  accuracy  macro avg  \\\n","precision          1.0              1.0             1.0       1.0        1.0   \n","recall             1.0              1.0             1.0       1.0        1.0   \n","f1-score           1.0              1.0             1.0       1.0        1.0   \n","support           19.0             15.0            16.0       1.0       50.0   \n","\n","           weighted avg  \n","precision           1.0  \n","recall              1.0  \n","f1-score            1.0  \n","support            50.0  \n","_______________________________________________\n","Confusion Matrix: \n"," [[19  0  0]\n"," [ 0 15  0]\n"," [ 0  0 16]]\n","\n","_______________________________________________\n","f1_score: \n"," 1.0\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"xSw3J3-12YQz"},"source":["## wine.csv"]},{"cell_type":"code","metadata":{"id":"GD28e3Aa2YQ0","outputId":"312c5cba-b396-4cb3-e12c-f37b8b33ad70"},"source":["df = pd.read_excel('../dataset/wine.xlsx', header= None)\n","df.head()\n","rows = len(df)\n","cols = len(df.columns)\n","\n","\n","df[14] = df[0]\n","for i in range(cols):\n","  df[i] = df[i+1]\n","df = df.drop([14], axis = 1)\n","\n","df.head(5)\n","\n","df = df.values.tolist() #convert dataframe to list of lists\n","test_attribute = []\n","for i in range(cols):\n","  test_attribute.append(i)\n","print(test_attribute)\n","test_value_type = []\n","for i in range(cols-1):\n","  test_value_type.append('numerical')\n","test_value_type.append('label')\n","\n","test_data_after = pre_process(df, test_attribute, test_value_type)\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","0 : [12.2, 12.79]\n","1 : [1.43, 2.31]\n","2 : [2.04]\n","3 : [18.0]\n","4 : [89.0]\n","5 : [1.85, 2.35]\n","6 : [0.99, 1.58, 2.33]\n","7 : [0.4]\n","8 : [1.28]\n","9 : [3.52, 7.6]\n","10 : [0.79, 0.98, 1.31]\n","11 : [2.12, 2.48]\n","12 : [470.0, 760.0, 990.0]\n"]}]},{"cell_type":"code","metadata":{"id":"Mu8cJJz82YQ2"},"source":["data = pd.DataFrame (test_data_after)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ANzCI-7N2YQ3"},"source":["X = data.drop(13, axis=1)\n","y = data[13]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UV_V1Vek2YQ4"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rloAIGoL2YQ4"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"-EsErh6y2YQ4","outputId":"63d9b06a-eb8f-4302-cb4a-e7ec4f8c49ad"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"mqfJvNYS2YQ5","outputId":"2a709d1a-9017-480c-a587-3dab61f6f43c"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 98.31%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                 1.0        2.0   3.0  accuracy  macro avg  weighted avg\n","precision   1.000000   0.960000   1.0  0.983051   0.986667      0.983729\n","recall      0.950000   1.000000   1.0  0.983051   0.983333      0.983051\n","f1-score    0.974359   0.979592   1.0  0.983051   0.984650      0.983007\n","support    20.000000  24.000000  15.0  0.983051  59.000000     59.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[19  1  0]\n"," [ 0 24  0]\n"," [ 0  0 15]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9830508474576272\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"aGMlNDl22YQ6"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"WveOvbQy2YQ6","outputId":"04073173-edc9-45d5-9bec-3b4031616899"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"5-DdmD3z2YQ6","outputId":"4b954f52-0213-49ec-be3f-368f3570d682"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_lib_pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_lib_pred_test, output_dict=True))\n","print(\"Test Result for liblinear solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_lib_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_lib_pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for liblinear solver:\n","================================================\n","Accuracy Score: 96.61%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","             1.0        2.0   3.0  accuracy  macro avg  weighted avg\n","precision   0.95   0.958333   1.0  0.966102   0.969444      0.966102\n","recall      0.95   0.958333   1.0  0.966102   0.969444      0.966102\n","f1-score    0.95   0.958333   1.0  0.966102   0.969444      0.966102\n","support    20.00  24.000000  15.0  0.966102  59.000000     59.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[19  1  0]\n"," [ 1 23  0]\n"," [ 0  0 15]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9661016949152542\n","\n"]}]},{"cell_type":"code","metadata":{"id":"6ItskKLh2YQ7","outputId":"7b641a9b-3383-44ca-a807-6e0ae400c7ad"},"source":["lr_saga = LogisticRegression(solver='saga') # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]},{"data":{"text/plain":["LogisticRegression(solver='saga')"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"TFiR3OuJ2YQ9","outputId":"5fb36f13-2884-48cb-ef6a-62db0f09ff78"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_saga_pred_test = lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_saga_pred_test, output_dict=True))\n","print(\"Test Result for saga solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_saga_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_saga_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_saga_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for saga solver:\n","================================================\n","Accuracy Score: 96.61%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","             1.0        2.0   3.0  accuracy  macro avg  weighted avg\n","precision   0.95   0.958333   1.0  0.966102   0.969444      0.966102\n","recall      0.95   0.958333   1.0  0.966102   0.969444      0.966102\n","f1-score    0.95   0.958333   1.0  0.966102   0.969444      0.966102\n","support    20.00  24.000000  15.0  0.966102  59.000000     59.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[19  1  0]\n"," [ 1 23  0]\n"," [ 0  0 15]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9661016949152542\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"4RRjd5u92YQ-"},"source":["## glass.csv"]},{"cell_type":"code","metadata":{"id":"lwo5xxjl2YQ_","outputId":"19190abe-2272-4e33-f93e-25e47bfdee9d"},"source":["df = pd.read_csv('../dataset/glass.csv', header= None)\n","df.head()\n","rows = len(df)\n","cols = len(df.columns)\n","\n","df = df.values.tolist() #convert dataframe to list of lists\n","test_attribute = []\n","for i in range(cols):\n","  test_attribute.append(i)\n","print(test_attribute)\n","test_value_type = []\n","for i in range(cols-1):\n","  test_value_type.append('numerical')\n","test_value_type.append('label')\n","test_data_after = pre_process(df, test_attribute, test_value_type)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","0 : [71.0, 147.0, 164.0, 177.0, 186.0]\n","1 : [1.51735, 1.518]\n","2 : [14.09]\n","3 : [2.71]\n","4 : [1.4, 1.79]\n","5 : [71.67666666666666, 73.54333333333334]\n","6 : [0.06, 0.62, 0.76]\n","7 : [7.08, 8.32, 10.09]\n","8 : [0.4]\n","9 : [0.17, 0.34]\n"]}]},{"cell_type":"code","metadata":{"id":"ZhwipEV02YRA"},"source":["data = pd.DataFrame (test_data_after)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VR6z_LYQ2YRB"},"source":["X = data.drop(10, axis=1)\n","y = data[10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lR_thEKT2YRB"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iUOWdpC2YRB"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"ccp-OdLS2YRC","outputId":"66ffaa11-73d3-4707-e886-f1d575fef990"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"kdEX7kIu2YRC","outputId":"9bb28f24-e379-4242-8430-a46a965b552d"},"source":["# Predict the class label using X_test\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 100.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","            1.0   2.0  3.0  5.0  6.0   7.0  accuracy  macro avg  weighted avg\n","precision   1.0   1.0  1.0  1.0  1.0   1.0       1.0        1.0           1.0\n","recall      1.0   1.0  1.0  1.0  1.0   1.0       1.0        1.0           1.0\n","f1-score    1.0   1.0  1.0  1.0  1.0   1.0       1.0        1.0           1.0\n","support    22.0  25.0  4.0  6.0  4.0  10.0       1.0       71.0          71.0\n","_______________________________________________\n","Confusion Matrix: \n"," [[22  0  0  0  0  0]\n"," [ 0 25  0  0  0  0]\n"," [ 0  0  4  0  0  0]\n"," [ 0  0  0  6  0  0]\n"," [ 0  0  0  0  4  0]\n"," [ 0  0  0  0  0 10]]\n","\n","_______________________________________________\n","f1_score: \n"," 1.0\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"umQzzzyq2YRD"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"HYtf7-7H2YRD","outputId":"41cd3afc-110c-41de-a260-cc6c2b728392"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"swZjyZmO2YRE","outputId":"d6e17c51-5cbe-475b-9911-54f9b9007ce5"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","lr_lib_pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_lib_pred_test, output_dict=True))\n","print(\"Test Result for liblinear solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_lib_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_lib_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for liblinear solver:\n","================================================\n","Accuracy Score: 83.10%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                 1.0        2.0       3.0       5.0   6.0        7.0  \\\n","precision   0.954545   0.733333  0.666667  1.000000  0.75   0.909091   \n","recall      0.954545   0.880000  0.500000  0.166667  0.75   1.000000   \n","f1-score    0.954545   0.800000  0.571429  0.285714  0.75   0.952381   \n","support    22.000000  25.000000  4.000000  6.000000  4.00  10.000000   \n","\n","           accuracy  macro avg  weighted avg  \n","precision  0.830986   0.835606      0.846351  \n","recall     0.830986   0.708535      0.830986  \n","f1-score   0.830986   0.719012      0.810195  \n","support    0.830986  71.000000     71.000000  \n","_______________________________________________\n","Confusion Matrix: \n"," [[21  1  0  0  0  0]\n"," [ 1 22  1  0  1  0]\n"," [ 0  2  2  0  0  0]\n"," [ 0  5  0  1  0  0]\n"," [ 0  0  0  0  3  1]\n"," [ 0  0  0  0  0 10]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.8309859154929577\n","\n"]}]},{"cell_type":"code","metadata":{"id":"KjlTmemY2YRE","outputId":"a2fbd631-2809-4eed-9b34-6baac94e7dd6"},"source":["lr_saga = LogisticRegression(solver='saga') # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]},{"data":{"text/plain":["LogisticRegression(solver='saga')"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"z28Hqi5-2YRF","outputId":"bba2a2c0-f104-4f3a-9079-8c2c3b4816ad"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_saga_pred_test = lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_saga_pred_test, output_dict=True))\n","print(\"Test Result for saga solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_saga_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_saga_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_saga_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for saga solver:\n","================================================\n","Accuracy Score: 95.77%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","            1.0        2.0       3.0       5.0  6.0   7.0  accuracy  \\\n","precision   1.0   0.925926  0.666667  1.000000  1.0   1.0  0.957746   \n","recall      1.0   1.000000  0.500000  0.833333  1.0   1.0  0.957746   \n","f1-score    1.0   0.961538  0.571429  0.909091  1.0   1.0  0.957746   \n","support    22.0  25.000000  4.000000  6.000000  4.0  10.0  0.957746   \n","\n","           macro avg  weighted avg  \n","precision   0.932099      0.955138  \n","recall      0.888889      0.957746  \n","f1-score    0.907010      0.954630  \n","support    71.000000     71.000000  \n","_______________________________________________\n","Confusion Matrix: \n"," [[22  0  0  0  0  0]\n"," [ 0 25  0  0  0  0]\n"," [ 0  2  2  0  0  0]\n"," [ 0  0  1  5  0  0]\n"," [ 0  0  0  0  4  0]\n"," [ 0  0  0  0  0 10]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9577464788732394\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"b-VeZgmX2YRG"},"source":["## Tic-Tac-Toe.csv"]},{"cell_type":"code","metadata":{"id":"3BQ4XO8Z2YRG","outputId":"e820d7e5-902a-40d4-e561-65d83a954704"},"source":["data_path = '../dataset/tic-tac-toe.data' # only change filename here for different datasets\n","scheme_path = '../dataset/tic-tac-toe.names'\n","data, attributes, value_type = read(data_path, scheme_path)\n","#random.shuffle(data)\n","df = pre_process(data, attributes, value_type)\n","# print(type(df))\n","# print(df)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["top-left-square : {'b': 1, 'o': 2, 'x': 3}\n","top-middle-square : {'b': 1, 'o': 2, 'x': 3}\n","top-right-square : {'b': 1, 'o': 2, 'x': 3}\n","middle-left-square : {'b': 1, 'o': 2, 'x': 3}\n","middle-middle-square : {'x': 1, 'o': 2, 'b': 3}\n","middle-right-square : {'x': 1, 'o': 2, 'b': 3}\n","bottom-left-square : {'b': 1, 'o': 2, 'x': 3}\n","bottom-middle-square : {'b': 1, 'o': 2, 'x': 3}\n","bottom-right-square : {'b': 1, 'o': 2, 'x': 3}\n"]}]},{"cell_type":"code","metadata":{"id":"L4kdp4R_2YRG"},"source":["df = pd.DataFrame(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"za5G9iTl2YRH","outputId":"6ebac891-87fa-4b89-bb40-4fe87e484077"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  1  2  3  4  5  6  7  8         9\n","0  3  3  3  3  2  2  3  2  2  positive\n","1  3  3  3  3  2  2  2  3  2  positive\n","2  3  3  3  3  2  2  2  2  3  positive\n","3  3  3  3  3  2  2  2  1  1  positive\n","4  3  3  3  3  2  2  1  2  1  positive"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"mHF3OUD62YRH","outputId":"30fc5d88-3bd6-428d-e305-9af36ac69283"},"source":["df.describe()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","      <td>958.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.222338</td>\n","      <td>2.133612</td>\n","      <td>2.222338</td>\n","      <td>2.133612</td>\n","      <td>1.688935</td>\n","      <td>1.866388</td>\n","      <td>2.222338</td>\n","      <td>2.133612</td>\n","      <td>2.222338</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.775569</td>\n","      <td>0.798966</td>\n","      <td>0.775569</td>\n","      <td>0.798966</td>\n","      <td>0.740882</td>\n","      <td>0.798966</td>\n","      <td>0.775569</td>\n","      <td>0.798966</td>\n","      <td>0.775569</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>2.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                0           1           2           3           4           5  \\\n","count  958.000000  958.000000  958.000000  958.000000  958.000000  958.000000   \n","mean     2.222338    2.133612    2.222338    2.133612    1.688935    1.866388   \n","std      0.775569    0.798966    0.775569    0.798966    0.740882    0.798966   \n","min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n","25%      2.000000    1.000000    2.000000    1.000000    1.000000    1.000000   \n","50%      2.000000    2.000000    2.000000    2.000000    2.000000    2.000000   \n","75%      3.000000    3.000000    3.000000    3.000000    2.000000    3.000000   \n","max      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n","\n","                6           7           8  \n","count  958.000000  958.000000  958.000000  \n","mean     2.222338    2.133612    2.222338  \n","std      0.775569    0.798966    0.775569  \n","min      1.000000    1.000000    1.000000  \n","25%      2.000000    1.000000    2.000000  \n","50%      2.000000    2.000000    2.000000  \n","75%      3.000000    3.000000    3.000000  \n","max      3.000000    3.000000    3.000000  "]},"execution_count":42,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"ir6--Npn2YRI","outputId":"831df285-643e-4b70-d195-3c489162d148"},"source":["df[9].unique()"],"execution_count":null,"outputs":[{"data":{"text/plain":["array(['positive', 'negative'], dtype=object)"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"auxFUIzH2YRI"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"3iKnd5122YRI"},"source":["X = df.drop(9, axis=1)\n","y = df[9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9a6id0A42YRJ"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoWtz1v62YRJ","outputId":"166450ad-0e4d-4d59-cd0b-af166011b975"},"source":["# Check the sample sizes\n","print(\"Train Set :\", X_train.shape, y_train.shape)\n","print(\"Test Set  :\", X_test.shape, y_test.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set : (641, 9) (641,)\n","Test Set  : (317, 9) (317,)\n"]}]},{"cell_type":"code","metadata":{"id":"Q3Dqilt92YRK","outputId":"67c9cc1a-a862-4a77-c3d8-3c721bd8f82d"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"Qb0UHPdA2YRK","outputId":"8e65cb23-538d-4245-d951-ebd8f9d4e3d8"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test)} \\n\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 0.9369085173501577 \n","\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","             negative    positive  accuracy   macro avg  weighted avg\n","precision    0.976744    0.922078  0.936909    0.949411      0.939668\n","recall       0.823529    0.990698  0.936909    0.907114      0.936909\n","f1-score     0.893617    0.955157  0.936909    0.924387      0.935355\n","support    102.000000  215.000000  0.936909  317.000000    317.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[ 84  18]\n"," [  2 213]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9369085173501577\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"KyOUtUh42YRL"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"rMHHyPyI2YRL"},"source":["X = df.drop(9, axis=1)\n","y = df[9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Klsf1-P_2YRL"},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RNNhC56z2YRM","outputId":"b8d7f6ab-377f-4eec-db60-e2484f6221ff"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"Ukv1SH0x2YRO","outputId":"d8ed2b1c-5421-4351-814f-da24c5ae9902"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_lib_pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_lib_pred_test, output_dict=True))\n","print(\"Test Result for liblinear solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_lib_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for liblinear solver:\n","================================================\n","Accuracy Score: 0.7066246056782335\n","\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","             negative    positive  accuracy   macro avg  weighted avg\n","precision    0.621622    0.717857  0.706625    0.669739      0.686892\n","recall       0.225490    0.934884  0.706625    0.580187      0.706625\n","f1-score     0.330935    0.812121  0.706625    0.571528      0.657292\n","support    102.000000  215.000000  0.706625  317.000000    317.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[ 23  79]\n"," [ 14 201]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.7066246056782335\n","\n"]}]},{"cell_type":"code","metadata":{"id":"6UUpUoGm2YRO","outputId":"cf9ea53e-2c5f-44f7-86a4-bad4810418ef"},"source":["lr_saga = LogisticRegression(solver='saga') # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]},{"data":{"text/plain":["LogisticRegression(solver='saga')"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"10M8Wcow2YRP","outputId":"517be09e-792c-4616-c70f-40f4d7780f4b"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_saga_pred_test = lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_saga_pred_test, output_dict=True))\n","print(\"Test Result for saga solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_saga_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_saga_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_saga_pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for saga solver:\n","================================================\n","Accuracy Score: 71.29%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","             negative    positive  accuracy   macro avg  weighted avg\n","precision    0.657143    0.719858  0.712934    0.688501      0.699678\n","recall       0.225490    0.944186  0.712934    0.584838      0.712934\n","f1-score     0.335766    0.816901  0.712934    0.576334      0.662088\n","support    102.000000  215.000000  0.712934  317.000000    317.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[ 23  79]\n"," [ 12 203]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.7129337539432177\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"g5LCTkb82YRP"},"source":["## zoo.csv"]},{"cell_type":"code","metadata":{"id":"1n2C-n012YRQ","outputId":"fa50c830-bc35-4785-f6c2-3923d1e3aa1a"},"source":["data_path = '../dataset/zoo.data' # only change filename here for different datasets\n","scheme_path = '../dataset/zoo.names'\n","data, attributes, value_type = read(data_path, scheme_path)\n","#random.shuffle(data)\n","df = pre_process(data, attributes, value_type)\n","# print(type(df))\n","# print(df)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["animal name : {'crab': 1, 'pitviper': 2, 'deer': 3, 'sealion': 4, 'wren': 5, 'octopus': 6, 'carp': 7, 'hare': 8, 'tuatara': 9, 'lion': 10, 'mongoose': 11, 'reindeer': 12, 'oryx': 13, 'leopard': 14, 'cavy': 15, 'toad': 16, 'porpoise': 17, 'cheetah': 18, 'lark': 19, 'rhea': 20, 'herring': 21, 'goat': 22, 'chub': 23, 'skimmer': 24, 'mink': 25, 'bass': 26, 'mole': 27, 'skua': 28, 'sole': 29, 'seawasp': 30, 'puma': 31, 'pony': 32, 'duck': 33, 'dove': 34, 'seahorse': 35, 'raccoon': 36, 'catfish': 37, 'gnat': 38, 'tortoise': 39, 'pheasant': 40, 'vampire': 41, 'newt': 42, 'ladybird': 43, 'flea': 44, 'crayfish': 45, 'crow': 46, 'platypus': 47, 'tuna': 48, 'polecat': 49, 'boar': 50, 'housefly': 51, 'moth': 52, 'hawk': 53, 'antelope': 54, 'vole': 55, 'piranha': 56, 'aardvark': 57, 'penguin': 58, 'vulture': 59, 'swan': 60, 'sparrow': 61, 'giraffe': 62, 'parakeet': 63, 'dogfish': 64, 'stingray': 65, 'ostrich': 66, 'flamingo': 67, 'lobster': 68, 'squirrel': 69, 'gorilla': 70, 'frog': 71, 'starfish': 72, 'elephant': 73, 'seasnake': 74, 'haddock': 75, 'kiwi': 76, 'girl': 77, 'gull': 78, 'seal': 79, 'wasp': 80, 'bear': 81, 'buffalo': 82, 'pike': 83, 'hamster': 84, 'lynx': 85, 'honeybee': 86, 'wallaby': 87, 'pussycat': 88, 'slowworm': 89, 'worm': 90, 'chicken': 91, 'wolf': 92, 'termite': 93, 'fruitbat': 94, 'clam': 95, 'dolphin': 96, 'slug': 97, 'opossum': 98, 'calf': 99, 'scorpion': 100}\n","hair : {'0': 1, '1': 2}\n","feathers : {'0': 1, '1': 2}\n","eggs : {'0': 1, '1': 2}\n","milk : {'0': 1, '1': 2}\n","airborne : {'0': 1, '1': 2}\n","aquatic : {'0': 1, '1': 2}\n","predator : {'0': 1, '1': 2}\n","toothed : {'0': 1, '1': 2}\n","backbone : {'0': 1, '1': 2}\n","breathes : {'0': 1, '1': 2}\n","venomous : {'0': 1, '1': 2}\n","fins : {'0': 1, '1': 2}\n","legs : {'6': 1, '8': 2, '4': 3, '5': 4, '2': 5, '0': 6}\n","tail : {'0': 1, '1': 2}\n","domestic : {'0': 1, '1': 2}\n","catsize : {'0': 1, '1': 2}\n"]}]},{"cell_type":"code","metadata":{"id":"YUj1MB3m2YRQ"},"source":["df = pd.DataFrame(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"VUj3ZRIi2YRR","outputId":"dfbb66b1-8124-4823-cc6f-9ad609aaad41"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>57</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>54</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>26</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>81</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16 17\n","0  57   2   1   1   2   1   1   2   2   2   2   1   1   3   1   1   2  1\n","1  54   2   1   1   2   1   1   1   2   2   2   1   1   3   2   1   2  1\n","2  26   1   1   2   1   1   2   2   2   2   1   1   2   6   2   1   1  4\n","3  81   2   1   1   2   1   1   2   2   2   2   1   1   3   1   1   2  1\n","4  50   2   1   1   2   1   1   2   2   2   2   1   1   3   2   1   2  1"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"XHdTeBHN2YRR","outputId":"3601f545-0d08-4c03-f1cf-023bf44046a4"},"source":["df[17].unique()"],"execution_count":null,"outputs":[{"data":{"text/plain":["array(['1', '4', '2', '7', '6', '5', '3'], dtype=object)"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"w2-G_VmP2YRS"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"HXaDuwO72YRS"},"source":["X = df.drop(17, axis=1)\n","y = df[17]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq41TKR82YRS"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IEXWrAUk2YRT","outputId":"298854a7-67e5-4b9e-89a5-927c6dd5bc51"},"source":["# Check the sample sizes\n","print(\"Train Set :\", X_train.shape, y_train.shape)\n","print(\"Test Set  :\", X_test.shape, y_test.shape)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set : (67, 17) (67,)\n","Test Set  : (34, 17) (34,)\n"]}]},{"cell_type":"code","metadata":{"id":"_--MshtP2YRT","outputId":"2dbc893b-d219-4a0b-8983-90830155bb2c"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"-MX_Tg8C2YRU","outputId":"fb2f9ff3-2a25-4c55-c067-d65f4d71d4ee"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test)} \\n\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 0.9411764705882353 \n","\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","              1    2    3         4         5    6    7  accuracy  macro avg  \\\n","precision   1.0  1.0  0.0  0.666667  0.666667  1.0  1.0  0.941176   0.761905   \n","recall      1.0  1.0  0.0  1.000000  1.000000  1.0  1.0  0.941176   0.857143   \n","f1-score    1.0  1.0  0.0  0.800000  0.800000  1.0  1.0  0.941176   0.800000   \n","support    17.0  3.0  2.0  2.000000  2.000000  5.0  3.0  0.941176  34.000000   \n","\n","           weighted avg  \n","precision      0.901961  \n","recall         0.941176  \n","f1-score       0.917647  \n","support       34.000000  \n","_______________________________________________\n","Confusion Matrix: \n"," [[17  0  0  0  0  0  0]\n"," [ 0  3  0  0  0  0  0]\n"," [ 0  0  0  1  1  0  0]\n"," [ 0  0  0  2  0  0  0]\n"," [ 0  0  0  0  2  0  0]\n"," [ 0  0  0  0  0  5  0]\n"," [ 0  0  0  0  0  0  3]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9411764705882353\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"r6akijl-2YRU"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"fphx1QWY2YRV"},"source":["X = df.drop(17, axis=1)\n","y = df[17]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bO_9c3JM2YRV"},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zccCa0SS2YRV","outputId":"362bba59-6e4c-4cfd-890e-ca78c1d8fa69"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"_uVYjv3G2YRW","outputId":"5dd0c3e3-0441-4af0-bf61-14ef7421ee15"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_lib_pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_lib_pred_test, output_dict=True))\n","print(\"Test Result for liblinear solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_lib_pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for liblinear solver:\n","================================================\n","Accuracy Score: 0.9411764705882353\n","\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                   1    2         3         4    5    6         7  accuracy  \\\n","precision   0.944444  1.0  1.000000  0.666667  1.0  1.0  1.000000  0.941176   \n","recall      1.000000  1.0  0.500000  1.000000  1.0  1.0  0.666667  0.941176   \n","f1-score    0.971429  1.0  0.666667  0.800000  1.0  1.0  0.800000  0.941176   \n","support    17.000000  3.0  2.000000  2.000000  2.0  5.0  3.000000  0.941176   \n","\n","           macro avg  weighted avg  \n","precision   0.944444      0.952614  \n","recall      0.880952      0.941176  \n","f1-score    0.891156      0.936695  \n","support    34.000000     34.000000  \n","_______________________________________________\n","Confusion Matrix: \n"," [[17  0  0  0  0  0  0]\n"," [ 0  3  0  0  0  0  0]\n"," [ 0  0  1  1  0  0  0]\n"," [ 0  0  0  2  0  0  0]\n"," [ 0  0  0  0  2  0  0]\n"," [ 0  0  0  0  0  5  0]\n"," [ 1  0  0  0  0  0  2]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.9411764705882353\n","\n"]}]},{"cell_type":"code","metadata":{"id":"2Ne-tM4-2YRW","outputId":"306866bd-9d88-4014-88a1-d36f82f6ed05"},"source":["lr_saga = LogisticRegression(solver='saga') # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]},{"data":{"text/plain":["LogisticRegression(solver='saga')"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"R9lPQ6Ru2YRX","outputId":"0a1b3148-69f9-4274-c277-12e1c8075e3f"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_saga_pred_test = lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_saga_pred_test, output_dict=True))\n","print(\"Test Result for saga solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_saga_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_saga_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_saga_pred_test, average = 'micro')}\\n\")\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for saga solver:\n","================================================\n","Accuracy Score: 61.76%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                   1     2    3         4    5    6    7  accuracy  macro avg  \\\n","precision   0.640000  0.60  0.0  0.500000  0.0  0.0  0.0  0.617647   0.248571   \n","recall      0.941176  1.00  0.0  1.000000  0.0  0.0  0.0  0.617647   0.420168   \n","f1-score    0.761905  0.75  0.0  0.666667  0.0  0.0  0.0  0.617647   0.311224   \n","support    17.000000  3.00  2.0  2.000000  2.0  5.0  3.0  0.617647  34.000000   \n","\n","           weighted avg  \n","precision      0.402353  \n","recall         0.617647  \n","f1-score       0.486345  \n","support       34.000000  \n","_______________________________________________\n","Confusion Matrix: \n"," [[16  0  0  1  0  0  0]\n"," [ 0  3  0  0  0  0  0]\n"," [ 1  1  0  0  0  0  0]\n"," [ 0  0  0  2  0  0  0]\n"," [ 1  1  0  0  0  0  0]\n"," [ 5  0  0  0  0  0  0]\n"," [ 2  0  0  1  0  0  0]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.6176470588235294\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"QQatGrjL2YRY"},"source":["## Teaching Assistant Evaluation"]},{"cell_type":"code","metadata":{"id":"5d_yD_Jj2YRY","outputId":"76588db3-ff0a-47ee-d135-5dc8591987a6"},"source":["data_path = '../dataset/tae.data' # only change filename here for different datasets\n","scheme_path = '../dataset/tae.names'\n","data, attributes, value_type = read(data_path, scheme_path)\n","#random.shuffle(data)\n","df = pre_process(data, attributes, value_type)\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Course_instructor : {'15': 1, '20': 2, '9': 3, '24': 4, '5': 5, '17': 6, '18': 7, '14': 8, '8': 9, '7': 10, '11': 11, '25': 12, '13': 13, '4': 14, '2': 15, '19': 16, '22': 17, '23': 18, '3': 19, '16': 20, '21': 21, '6': 22, '10': 23, '12': 24, '1': 25}\n","Course : {'15': 1, '20': 2, '9': 3, '24': 4, '5': 5, '17': 6, '14': 7, '18': 8, '8': 9, '7': 10, '11': 11, '25': 12, '13': 13, '4': 14, '2': 15, '19': 16, '22': 17, '23': 18, '3': 19, '16': 20, '21': 21, '6': 22, '10': 23, '26': 24, '12': 25, '1': 26}\n"," Class_size : [24.0, 45.0]\n"]}]},{"cell_type":"code","metadata":{"id":"UKTPPXlD2YRY"},"source":["df = pd.DataFrame(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pcXeHGIb2YRZ","outputId":"5385cb54-07d6-4a6f-a9ff-d895dab162c3"},"source":["df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>18</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>18</td>\n","      <td>19</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0   1   2  3  4  5\n","0  1  18  19  1  1  3\n","1  2   1  19  1  1  3\n","2  1  18  19  2  3  3\n","3  1   5  15  2  2  3\n","4  2  10  11  2  3  3"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"LbNoU0kP2YRZ","outputId":"f44ba563-57b5-40b6-8915-ef0b7ba0d602"},"source":["df[5].unique()"],"execution_count":null,"outputs":[{"data":{"text/plain":["array(['3', '2', '1'], dtype=object)"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"Ub-x_Va32YRa"},"source":["X = df.drop(5, axis=1)\n","y = df[5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vjso845Q2YRa"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ERvn5zYh2YRa"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"_1DDR4K62YRb","outputId":"5ca1dcc0-27e3-4a13-ee99-2d3c9b1391d9"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"Lgc1OiYh2YRb","outputId":"b67dae53-5a41-4dd9-b983-9b4d9d0f1486"},"source":["pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 60.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                   1          2          3  accuracy  macro avg  weighted avg\n","precision   0.500000   0.588235   0.888889       0.6   0.659041      0.660458\n","recall      0.705882   0.625000   0.470588       0.6   0.600490      0.600000\n","f1-score    0.585366   0.606061   0.615385       0.6   0.602270      0.602195\n","support    17.000000  16.000000  17.000000       0.6  50.000000     50.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[12  5  0]\n"," [ 5 10  1]\n"," [ 7  2  8]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.6\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"FQGMqNUP2YRe"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"vVbDS9SQ2YRe","outputId":"8056216c-3cfa-4c78-f261-f1e154539698"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"87tSdIvm2YRf","outputId":"5627f597-848d-4494-8bd8-8327cdf349ea"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_lib_pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_lib_pred_test, output_dict=True))\n","print(\"Test Result for liblinear solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_lib_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_lib_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for liblinear solver:\n","================================================\n","Accuracy Score: 36.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                   1          2          3  accuracy  macro avg  weighted avg\n","precision   0.250000   0.388889   0.437500      0.36   0.358796      0.358194\n","recall      0.235294   0.437500   0.411765      0.36   0.361520      0.360000\n","f1-score    0.242424   0.411765   0.424242      0.36   0.359477      0.358431\n","support    17.000000  16.000000  17.000000      0.36  50.000000     50.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[4 7 6]\n"," [6 7 3]\n"," [6 4 7]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.36\n","\n"]}]},{"cell_type":"code","metadata":{"id":"LRXnbo0V2YRg","outputId":"f296f1d3-3b97-4331-b490-9691e596f9ee"},"source":["lr_saga = LogisticRegression(solver='saga') # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]},{"data":{"text/plain":["LogisticRegression(solver='saga')"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"xfBFqJdf2YRg","outputId":"bf14c7bf-2641-4717-d6a2-f2dfee5b7786"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","# Didn't tune the hyperparameter\n","lr_saga_pred_test = lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_saga_pred_test, output_dict=True))\n","print(\"Test Result for saga solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_saga_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_saga_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_saga_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for saga solver:\n","================================================\n","Accuracy Score: 32.00%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                   1          2          3  accuracy  macro avg  weighted avg\n","precision   0.187500   0.411765   0.352941      0.32   0.317402      0.315515\n","recall      0.176471   0.437500   0.352941      0.32   0.322304      0.320000\n","f1-score    0.181818   0.424242   0.352941      0.32   0.319667      0.317576\n","support    17.000000  16.000000  17.000000      0.32  50.000000     50.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[3 6 8]\n"," [6 7 3]\n"," [7 4 6]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.32\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"nxFRn8Cp2YRh"},"source":["## Breast Cancer Coimbra Data Set.csv"]},{"cell_type":"code","metadata":{"id":"C71_MPGI2YRi","outputId":"35a44479-6c56-43d7-f79c-5bdc7b375087"},"source":["data = pd.read_csv('../Dataset/Breast Cancer Coimbra Data Set.csv')\n","data = data.values.tolist()\n","for i in range(len(data)):\n","    data[i][-1] = str(data[i][-1])\n","attributes = ['Age','BMI','Glucose','Insulin','HOMA','Leptin','Adiponectin','Resistin\tMCP.1','Classification']\n","value_type = ['numerical','numerical','numerical','numerical','numerical','numerical','numerical','numerical','label']\n","\n","d = pre_process(data, attributes, value_type)\n","data = pd.DataFrame(d)\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Age : [38.0]\n","BMI : [25.106252846666667, 31.842505693333337]\n","Glucose : [92.0]\n","Insulin : [21.107999999999997, 39.784]\n","HOMA : [2.241625267]\n","Leptin : [32.96733333333333, 61.623666666666665]\n","Adiponectin : [13.784013333333334, 25.91200666666667]\n","Resistin\tMCP.1 : [29.506666666666668, 55.803333333333335]\n"]}]},{"cell_type":"code","metadata":{"id":"Yz56Lzkn2YRi","outputId":"6a84a8af-86e4-46e7-f7c8-0ce97c052015"},"source":["data.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>468.786</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>554.697</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>928.220</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>773.920</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>530.410</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  1  2  3  4  5  6  7        8    9\n","0  2  1  1  1  1  1  1  1  468.786  1.0\n","1  2  1  1  1  1  1  2  1  554.697  1.0\n","2  2  1  1  1  1  1  1  1  928.220  1.0\n","3  2  1  1  1  1  1  1  1  773.920  1.0\n","4  2  1  1  1  1  1  1  1  530.410  1.0"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"kuwfi7cn2YRj"},"source":["X = data.drop(9, axis=1)\n","y = data[9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKbpD2AS2YRm"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kqF4s9fL2YRn"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"tGpUE5cB2YRn","outputId":"d9a36536-f918-47aa-d7c3-e4d2de7b09ca"},"source":["from sklearn.ensemble import RandomForestClassifier\n","rf_clf = RandomForestClassifier(n_estimators=90)\n","rf_clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"data":{"text/plain":["RandomForestClassifier(n_estimators=90)"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"eGfsD3Hi2YRo","outputId":"e9390091-1e4f-4202-a858-38fa4b9f2089"},"source":["# Predict the class label using X_test\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","pred_test = rf_clf.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, pred_test, output_dict=True))\n","print(\"Test Result:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result:\n","================================================\n","Accuracy Score: 68.42%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                 1.0   2.0  accuracy  macro avg  weighted avg\n","precision   0.666667   0.7  0.684211   0.683333      0.684211\n","recall      0.666667   0.7  0.684211   0.683333      0.684211\n","f1-score    0.666667   0.7  0.684211   0.683333      0.684211\n","support    18.000000  20.0  0.684211  38.000000     38.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[12  6]\n"," [ 6 14]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.6842105263157895\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"3QZPMhBU2YRp"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"cpJDjY-L2YRq","outputId":"a88d6d65-49cc-4d03-f728-9f5289305cc0"},"source":["from sklearn.linear_model import LogisticRegression\n","lr_lib = LogisticRegression(solver='liblinear') #good choice for smaller dataset\n","lr_lib_fit = lr_lib.fit(X_train,y_train)\n","lr_lib_fit"],"execution_count":null,"outputs":[{"data":{"text/plain":["LogisticRegression(solver='liblinear')"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"rfk-ZGIA2YRs","outputId":"543b094f-462e-4426-cbff-9268b5309126"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","lr_lib_pred_test = lr_lib_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_lib_pred_test, output_dict=True))\n","print(\"Test Result for liblinear solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_lib_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_lib_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_lib_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for liblinear solver:\n","================================================\n","Accuracy Score: 55.26%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","                 1.0        2.0  accuracy  macro avg  weighted avg\n","precision   0.533333   0.565217  0.552632   0.549275      0.550114\n","recall      0.444444   0.650000  0.552632   0.547222      0.552632\n","f1-score    0.484848   0.604651  0.552632   0.544750      0.547903\n","support    18.000000  20.000000  0.552632  38.000000     38.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[ 8 10]\n"," [ 7 13]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.5526315789473685\n","\n"]}]},{"cell_type":"code","metadata":{"id":"0SfUNHNJ2YRt","outputId":"f2f861f3-9c7c-437f-cef6-5152f3252097"},"source":["lr_saga = LogisticRegression(solver='saga') # Used for multi class problem\n","lr_saga_fit = lr_saga.fit(X_train,y_train)\n","lr_saga_fit"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\"The max_iter was reached which means \"\n"]},{"data":{"text/plain":["LogisticRegression(solver='saga')"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"UlqtA6gv2YRv","outputId":"0eaf898b-b3cb-4bc8-d35e-1bec5a08ccd8"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n","lr_saga_pred_test = lr_saga_fit.predict(X_test)\n","clf_report_test = pd.DataFrame(classification_report(y_test, lr_saga_pred_test, output_dict=True))\n","print(\"Test Result for saga solver:\\n================================================\")        \n","print(f\"Accuracy Score: {accuracy_score(y_test, lr_saga_pred_test) * 100:.2f}%\")\n","print(\"_______________________________________________\")\n","print(f\"CLASSIFICATION REPORT:\\n{clf_report_test}\")\n","print(\"_______________________________________________\")\n","print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, lr_saga_pred_test)}\\n\")\n","print(\"_______________________________________________\")\n","print(f\"f1_score: \\n {f1_score(y_test, lr_saga_pred_test, average = 'micro')}\\n\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Test Result for saga solver:\n","================================================\n","Accuracy Score: 52.63%\n","_______________________________________________\n","CLASSIFICATION REPORT:\n","            1.0        2.0  accuracy  macro avg  weighted avg\n","precision   0.0   0.526316  0.526316   0.263158      0.277008\n","recall      0.0   1.000000  0.526316   0.500000      0.526316\n","f1-score    0.0   0.689655  0.526316   0.344828      0.362976\n","support    18.0  20.000000  0.526316  38.000000     38.000000\n","_______________________________________________\n","Confusion Matrix: \n"," [[ 0 18]\n"," [ 0 20]]\n","\n","_______________________________________________\n","f1_score: \n"," 0.5263157894736842\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","metadata":{"id":"k8qV4c0L2YRw"},"source":[""],"execution_count":null,"outputs":[]}]}